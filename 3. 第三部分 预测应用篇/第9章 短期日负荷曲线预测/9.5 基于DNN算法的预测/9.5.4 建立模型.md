```python
init = keras.initializers.glorot_uniform(seed=1)
simple_adam = keras.optimizers.Adam()
model = keras.models.Sequential()
model.add(keras.layers.Dense(units=512, input_dim=1434, kernel_initializer=init, activation='relu'))
model.add(keras.layers.Dense(units=256, kernel_initializer=init, activation='relu'))
model.add(keras.layers.Dense(units=128, kernel_initializer=init, activation='relu'))
model.add(keras.layers.Dropout(0.1))
model.add(keras.layers.Dense(units=96, kernel_initializer=init, activation='tanh'))
model.compile(loss='mse', optimizer=simple_adam, metrics=['accuracy'])
model.fit(train_x, train_y, epochs=1000, batch_size=7, shuffle=True, verbose=True)
# Epoch 1/1000
# 351/351 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.0427
# Epoch 2/1000
# 351/351 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.0969
# Epoch 3/1000
# 351/351 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.0969
# ......
# Epoch 1000/1000
# 351/351 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.3476
```
