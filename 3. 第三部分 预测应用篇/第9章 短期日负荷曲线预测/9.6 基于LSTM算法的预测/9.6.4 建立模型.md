```python
from keras.layers import LSTM, Dense
from keras.models import Sequential
import keras
model = Sequential()
init = keras.initializers.glorot_uniform(seed=90)
model.add(LSTM(128, input_shape=(SEQLEN, dim_in), activation='relu', kernel_initializer=init, recurrent_dropout=0.01))
model.add(Dense(dim_out, activation='linear'))
model.compile(loss='mse', optimizer='rmsprop')
history = model.fit(X_train, Y_train, epochs=2000, batch_size=7, validation_split=0)
# Epoch 1/2000
# 351/351 [==============================] - 1s 4ms/step - loss: 0.0549
# Epoch 2/2000
# 351/351 [==============================] - 1s 2ms/step - loss: 0.0336
# Epoch 3/2000
# 351/351 [==============================] - 1s 1ms/step - loss: 0.0293
# ...
# Epoch 2000/2000
# 351/351 [==============================] - 1s 2ms/step - loss: 6.9224e-04
```

