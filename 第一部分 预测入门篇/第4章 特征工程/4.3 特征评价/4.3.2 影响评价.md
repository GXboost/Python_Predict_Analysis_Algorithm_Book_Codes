```python
import pandas as pd
from scipy import stats
iris = pd.read_csv("iris.csv")
stats.pearsonr(iris['Sepal.Length'], iris['Petal.Length'])
# (0.8717537758865832, 1.0386674194497583e-47)
```

```python
import matplotlib.pyplot as plt
import numpy as np
x=np.linspace(-1,1,50)
y=x**2
plt.plot(x,y,'o')
plt.xlabel('$x$')
plt.ylabel('$y$')
plt.show()
```

```python
stats.pearsonr(x, y)
# (-1.9448978228488063e-16, 1.0)
```

```python
from scipy.spatial.distance import correlation as dcor
dcor(x,y)
# 1.0
```

```python
import pandas as pd
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
iris = pd.read_csv("iris.csv")
iris.columns = ['_'.join(x.split('.')) for x in iris.columns]
anova_lm(ols('Sepal_Width~C(Species)', iris).fit())
```

```python
import numpy as np
def gains(u, v):
    ent_u = [np.sum([p*np.log2(1/p) for p in ct/np.sum(ct)]) for ct in [np.unique(u,return_counts=True)[1]]][0]
    v_id,v_ct = np.unique(v,return_counts=True)
    ent_u_m = [np.sum([p*np.log2(1/p) for p in ct/np.sum(ct)]) for ct in [np.unique(u[v==m],return_counts=True)[1] for m in v_id]]
    return ent_u - np.sum(np.array(ent_u_m)*(v_ct/np.sum(v_ct)))

def disc(u, x):
    sorted_x = np.sort(x)
    max_gains, max_tmp = 0, None
    for e in sorted_x:
        tmp = np.zeros(len(x))
        tmp[x>e]=1
        tmp_gain = gains(u,tmp)
        if tmp_gain > max_gains:
            max_gains,max_tmp  = tmp_gain, tmp
    return max_tmp
```

```python
import pandas as pd
iris = pd.read_csv("iris.csv")
for col in iris.columns[0:-1]:
    iris[col] = disc(iris.Species,iris[col]).astype("int")
iris.head()
```

```python
iris.columns=["S1","S2","P1","P2","Species"]
gains(iris['Species'],iris['S1'])
# 0.5572326878069265
```

```python
gains(iris['Species'],iris['S2'])
# 0.28312598916883114
gains(iris['Species'],iris['P1'])
# 0.9182958340544892
gains(iris['Species'],iris['P2'])
# 0.9182958340544892
```

```python
def gainsR(u,v):
    ent_v = [np.sum([p*np.log2(1/p) for p in ct/np.sum(ct)]) for ct in [np.unique(v,return_counts=True)[1]]][0]
    return gains(u,v)/ent_v

iris['P2']=range(iris.shape[0])
# 计算信息增益，并排序
gains(iris['Species'],iris['S1'])
# 0.5572326878069265
gains(iris['Species'],iris['S2'])
# 0.28312598916883114
gains(iris['Species'],iris['P1'])
# 0.9182958340544892
gains(iris['Species'],iris['P2'])
# 1.5849625007211559
# 重要性次序为：P2 > P1 > S1 > S2

# 计算信息增益率，并排序
gainsR(iris['Species'],iris['S1'])
# 0.5762983610929974
gainsR(iris['Species'],iris['S2'])
# 0.35129384185463564
gainsR(iris['Species'],iris['P1'])
# 0.9999999999999999
gainsR(iris['Species'],iris['P2'])
# 0.21925608713979675
# 重要性次序为：P1 > S1 > S2 > P2
```

```python
from  scipy.stats import chi2_contingency
import numpy as np
import pandas as pd
iris = pd.read_csv("iris.csv")
for col in iris.columns[0:-1]:
    iris[col] = disc(iris.Species,iris[col]).astype("int")
iris['D']=1
chi_data = np.array(iris.pivot_table(values='D', index='Sepal.Width', columns='Species',aggfunc='sum'))
chi = chi2_contingency(chi_data)
print('chisq-statistic=%.4f, p-value=%.4f, df=%i expected_frep=%s'%chi)
# chisq-statistic=57.1155, p-value=0.0000, df=2 expected_frep=[[37.66 37.66 37.66]
# [12.33 12.33 12.33]]
```

